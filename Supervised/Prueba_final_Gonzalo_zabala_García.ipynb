{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Prueba_final_Gonzalo_zabala_García.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GZabalaG/AIMaster/blob/main/Supervised/Prueba_final_Gonzalo_zabala_Garc%C3%ADa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wTuACVMK5Dp"
      },
      "source": [
        "# PRUEBA FINAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QKLEM8GLgXT",
        "outputId": "875201bc-a585-42fe-e145-386d6ea3e003"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8yrh9JbK5Dr"
      },
      "source": [
        "Información general:\n",
        "* La entrega consistirá en un archivo .ipynb siguiendo las instrucciones de este notebook.\n",
        "* Peso en la asignatura: 40% de la nota final.\n",
        "* Fecha de vencimiento: 22/07/2021, a las 23:59h (hora peninsular). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P6cJVJjK5Ds"
      },
      "source": [
        "**Instrucciones para cumplimentar el notebook:**\n",
        "* Descargar este notebook, que servirá como base para la entrega.\n",
        "* **No hay que modificar las celdas** que vienen en la hoja de actividades. Para contestar a las preguntas, se deben añadir celdas inmediatamente después de cada pregunta.\n",
        "* Para la nota se valorará tanto la consecución de la respuesta adecuada como el estilo y adecuación del código fuente, así como la inclusión de comentarios apropiados.\n",
        "* **No está permitido compartir los resultados de una actividad** con l@s compañer@s. Hacerlo puede suponer suspender la asignatura y enfrentarse a medidas disciplinarias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq_p2xCEK5Ds"
      },
      "source": [
        "### Ejercicio 1 (2 puntos)\n",
        "Utilizar el conjunto de datos \"dataset_1.npy\" para resolver el ejercicio. Tener en cuenta que la última columna corresponde a la clase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWVfrdjCK5Ds"
      },
      "source": [
        "#### 1.a) Imputación de valores ausentes (1 punto)\n",
        "\n",
        "Consideraciones:\n",
        "- En aquellas instancias (filas) que contengan UN ÚNICO VALOR NaN en alguno de sus atributos (columnas), se imputará dicho valor.\n",
        " * Si el atributo corresponde a una variable discreta, se imputará el valor utilizando la moda de dicho atributo. \n",
        " * Si el atributo corresponde a una variable continua, se imputará el valor utilizando la media de dicho atributo. \n",
        "- Aquellas instancias (filas) que contengan MÁS DE UN VALOR NaN en sus atributos, deberán ser eliminadas por completo. \n",
        "\n",
        "Los outputs deberán ser: \n",
        "- Una matriz X de dimensiones M x N, donde M será el número de instancias y N, el de atributos.\n",
        "- Un vector y de dimensiones M. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqHAY1XsmiRg"
      },
      "source": [
        "#### Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYqx4tP4K5Dt",
        "outputId": "7545a27a-fda0-4c2d-b24e-c640a669926d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.load('/content/drive/MyDrive/Master IA/Aprendizaje Supervisado/actividal_final/dataset_1.npy')\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.          4.          1.         ...  8.2603626   7.37490176\n",
            "   0.        ]\n",
            " [ 0.          4.          0.         ... 10.9370737  10.30131004\n",
            "   0.        ]\n",
            " [ 0.          3.          1.         ... 10.69134847 11.45671439\n",
            "   0.        ]\n",
            " ...\n",
            " [ 0.          2.          0.         ...  1.94458971  8.88390924\n",
            "   0.        ]\n",
            " [ 0.          3.          2.         ...  1.92895933  9.03304966\n",
            "   1.        ]\n",
            " [ 0.          4.          0.         ...  2.0478487   8.86096477\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lILYyzyPmm7v"
      },
      "source": [
        "#### Información sobre el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm8sg4Mimr4Z",
        "outputId": "a7d3edc2-f916-4e0a-c2ed-aa0516f5b8ab"
      },
      "source": [
        "print('Shape:', data.shape)\n",
        "\n",
        "print('\\n--------------\\n')\n",
        "\n",
        "print('Clases:', np.unique(data[:,-1]))\n",
        "\n",
        "print('\\n--------------\\n')\n",
        "print('Continuos | Categorical columns:\\n')\n",
        "\n",
        "i = 0\n",
        "column_types = []\n",
        "for column in data.T:\n",
        "  count_values = len(np.unique(column))\n",
        "  rate = count_values / data.shape[0]\n",
        "  value_type = 'Categorical' if rate < 0.1 else 'Continuous'\n",
        "  column_types.append(value_type)\n",
        "  print('Column:', i, '| Unique values:', count_values, '|', value_type)\n",
        "  i+=1\n",
        "\n",
        "print('\\n--------------\\n')\n",
        "print('Missing values:\\n')\n",
        "\n",
        "i = 0\n",
        "for column in data.T:\n",
        "  print('Column:', i, ' | Missing values', np.count_nonzero(np.isnan(column)))\n",
        "  i+=1"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: (500, 9)\n",
            "\n",
            "--------------\n",
            "\n",
            "Clases: [0. 1.]\n",
            "\n",
            "--------------\n",
            "\n",
            "Continuos | Categorical columns:\n",
            "\n",
            "Column: 0 | Unique values: 8 | Categorical\n",
            "Column: 1 | Unique values: 10 | Categorical\n",
            "Column: 2 | Unique values: 12 | Categorical\n",
            "Column: 3 | Unique values: 13 | Categorical\n",
            "Column: 4 | Unique values: 12 | Categorical\n",
            "Column: 5 | Unique values: 500 | Continuous\n",
            "Column: 6 | Unique values: 500 | Continuous\n",
            "Column: 7 | Unique values: 377 | Continuous\n",
            "Column: 8 | Unique values: 2 | Categorical\n",
            "\n",
            "--------------\n",
            "\n",
            "Missing values:\n",
            "\n",
            "Column: 0  | Missing values 6\n",
            "Column: 1  | Missing values 5\n",
            "Column: 2  | Missing values 5\n",
            "Column: 3  | Missing values 5\n",
            "Column: 4  | Missing values 5\n",
            "Column: 5  | Missing values 7\n",
            "Column: 6  | Missing values 5\n",
            "Column: 7  | Missing values 5\n",
            "Column: 8  | Missing values 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIuzeP0owTNz"
      },
      "source": [
        "Filling NaNs..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl_TmtXIoRtw",
        "outputId": "2ac09779-66b7-4d68-c77f-81cd5e282a8a"
      },
      "source": [
        "i = 0\n",
        "for column in data.T:\n",
        "  if (column_types[i] == 'Categorical'):\n",
        "    #Replace nans with mode\n",
        "  else:\n",
        "    #Replace nans with mean"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Categorical', 'Categorical', 'Categorical', 'Categorical', 'Categorical', 'Continuous', 'Continuous', 'Continuous', 'Categorical']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9llYwyUK5Dt"
      },
      "source": [
        "#### 1.b) Eliminación de valores outliers EXTREMOS (1 punto)\n",
        "- Aplicar el método de Elliptic Envelope fijando una semilla en 42\n",
        "- Utilizar el diagrama de caja y bigotes para establecer los umbrales de decisión\n",
        "- Plotear el diagrama obtenido a partir de las puntuaciones calculadas con el método Elliptic Envelope\n",
        "- Eliminar las instancias que contengan valores outliers extremos\n",
        "\n",
        "Los outputs deberán ser: \n",
        "- Una matriz X de dimensiones M' x N, donde M' será el nuevo número de instancias y N, el de atributos.\n",
        "- Un vector y de dimensiones M'. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylfLXenYK5Du"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7apUwpysK5Du"
      },
      "source": [
        "### Ejercicio 2 (1.5 puntos)\n",
        "Utilizar el conjunto de datos \"dataset_2.npy\" para resolver el ejercicio. Tener en cuenta que la última columna corresponde a la clase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4YFYF3WK5Du"
      },
      "source": [
        "#### 2.a) Partición de datos externa (0.5 puntos)\n",
        "Realizar una partición externa de tipo hold-out seleccionando un 20% de los datos para test (fijar una semilla en 42). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djHKSt4pK5Dv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9P67R1cK5Dv"
      },
      "source": [
        "#### 2.b) Selección de atributos sobre el conjunto de entrenamiento (0.5 puntos)\n",
        "Aplicar el método de VarianceThreshold con un umbral de 0.2 en el conjunto de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dOuHyVnK5Dv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPLY7tgLK5Dv"
      },
      "source": [
        "#### 2.c) Estandarización de los datos de entrenamiento (0.5 puntos)\n",
        "Utilizar el método StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H95uo4gqK5Dv"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht6j7mV-K5Dv"
      },
      "source": [
        "### Ejercicio 3 (2 puntos)\n",
        "Se requieren los resultados del ejercicio anterior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT8bzkOnK5Dw"
      },
      "source": [
        "#### 3.a) Comparación de modelos de clasifición mediante validación cruzada (0.5 puntos)\n",
        "Aplicar una validación cruzada interna de K=5 bolsas para optimizar y comparar la capacidad predictiva de los siguientes modelos: Regresión logística, Árboles de decisión y Support vector machine. (Fijar en todos una semilla en 42). La comparación debe realizarse en términos de exactitud proporcionando resultados de media +- desviación estándar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEBVFTghK5Dw"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNseyPRzK5Dw"
      },
      "source": [
        "#### 3.b) Evaluación de los modelos sobre el conjunto de test (1.5 puntos)\n",
        "- Entrenar los modelos anteriores utilizando todos los datos de entrenamiento y evaluar su rendimiento sobre el conjunto de test.\n",
        "- Mostrar en una figura la comparación de las curvas ROC obtenidas para cada modelo.\n",
        "- Crear una tabla donde se muestren los resultados de todos los modelos.\n",
        " * Las filas serán: Precisión, Sensibilidad, F-score, Exactitud y AUC\n",
        " * Las columnas serán: LR, Tree y SVM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53I9kuZXK5Dw"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9IYsPR9K5Dw"
      },
      "source": [
        "### Ejercicio 4 (2 puntos)\n",
        "Utilizar el conjunto de datos \"fish_dataset\" para resolver el ejercicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr4UZUEmK5Dw"
      },
      "source": [
        "#### 4.a) Procesado de imagen previo a la extracción de características (1 punto)\n",
        "Crear una función llamada \"cropping_function\" donde: \n",
        "- Los inputs sean la imagen RGB de un pez y su máscara correspondiente.\n",
        "- El output sea el crop de la bounding box de la imagen original orientada en el eje horizontal.\n",
        "\n",
        "Para ello, se pide:\n",
        "- Calcular la orientación del objeto a caracterizar.\n",
        "- Hacer una conversión siguiendo la siguiente fórmula:\n",
        " * angle = (orientation*90)/(math.pi/2), utiliza \"import math\"\n",
        "   -  Si 'angle' es mayor que 0, la orientación será igual a 90-angle\n",
        "   -  Si no, la orientación será igual a -(90+angle)\n",
        "- Aplicar una transformación geométrica de rotación para orientar horizontalmente el objeto de interés.\n",
        "- Hacer un crop de la boundingbox de la imagen original RGB, que será el output de la función"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2ZYJymFK5Dx"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kWMRaMzK5Dx"
      },
      "source": [
        "#### 4.b) Extracción de características de textura basadas en el descriptor Local Binary Pattern (1 punto)\n",
        "Crear un bucle for en el que:\n",
        " - Se lean las imágenes RGB y sus máscaras\n",
        " - Se extraiga el crop de la imagen RGB horizontal llamando a la función creada en el apartado anterior\n",
        " - Se obtenga la imagen LBP\n",
        " - Se muestre un subplot con el crop de la imagen RGB horizontal y su imagen LBP\n",
        " - Se calcule el histograma relativo a las características LBP. \n",
        "\n",
        "Plotear en una figura los 3 histogramas LBP obtenidos para analizar visualmente las diferencias en función del tipo de pez."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDeA8CuRK5Dx"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv4rDpEzK5Dx"
      },
      "source": [
        "### Ejercicio 5 (2.5 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOBXhW5DK5Dy"
      },
      "source": [
        "Crear un programa, con comentarios que aclaren el código, donde se computen las métricas MAE, RMSE y MAPE aplicando los regresores OLS y KNN en al menos tres datasets de regresión (a elegir los que se deseen). Se debe llevar a cabo una partición externa de tipo hold-out y una validación cruzada interna con K=10 bolsas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7e2vmOoK5Dy"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}