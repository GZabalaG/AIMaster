{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1: Demostrar o refutar equivalencia equivalencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado a) \n",
    "\n",
    "Predicado 1: $ \\overline{\\exists x:\\overline{\\overline{p\\left( x\\right) }\\vee \\overline{q\\left( x\\right) }}} $\n",
    "\n",
    "Predicado 2: $ \\left[ \\forall x,\\overline{p\\left( x\\right) }\\right] \\vee\\left[ \\forall x,\\overline{q\\left( x\\right) }\\right] $\n",
    "\n",
    "Resolvemos Predicado 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: $ \\overline{\\exists x:\\overline{\\overline{p\\left( x\\right) }\\vee \\overline{q\\left( x\\right) }}} $ -> (Aplicamos leyes de Morgan) \n",
    "\n",
    "2: $ \\overline{\\exists x:\\overline{\\overline{p\\left( x\\right) }}\\wedge \\overline{\\overline{q\\left( x\\right) }}} $ -> (Doble negación)\n",
    "\n",
    "3: $ \\overline{\\exists x:p\\left( x\\right) \\wedge q\\left( x\\right) } $ -> (Predicado: $ \\left[ \\overline{\\exists x:p\\left( x\\right) }\\right] \\leftrightarrow \\left[ \\forall x:\\overline{p\\left( x\\right) }\\right] $)\n",
    "\n",
    "4: $ \\forall x:\\overline{p\\left( x\\right) \\wedge q\\left( x\\right) } $ -> (Aplicamos leyes de Morgan) \n",
    "\n",
    "5: $ \\left[ \\forall x:\\overline{p\\left( x\\right) }\\vee \\overline{q\\left( x\\right) }\\right] $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a): Resulta una implicación ya que:\n",
    "\n",
    "$ \\left[ \\forall x,\\overline{p\\left( x\\right) }\\right] \\vee\\left[ \\forall x,\\overline{q\\left( x\\right) }\\right] \\models \\left[ \\forall x:\\overline{p\\left( x\\right) }\\vee \\overline{q\\left( x\\right) }\\right] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado b) \n",
    "\n",
    "Predicado 1: $ \\overline{\\forall x, \\exists y:\\left[ \\left( p\\left( x,y\\right) \\wedge q\\left( x,y\\right) \\right) \\rightarrow r\\left( x,y\\right) \\right] } $\n",
    "\n",
    "Predicado 2: $ \\exists x:\\left[ \\left( \\forall y,p\\left( x,y\\right) \\right) \\wedge \\left( \\forall y,q\\left( x,y\\right) \\right) \\wedge \\left( \\forall y,\\overline{r\\left( x,y\\right) }\\right) \\right] $\n",
    "\n",
    "Resolvemos Predicado 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: $ \\overline{\\forall x, \\exists y:\\left[ \\left( p\\left( x,y\\right) \\wedge q\\left( x,y\\right) \\right) \\rightarrow r\\left( x,y\\right) \\right] } $ -> (Resolvemos la implicación)\n",
    "\n",
    "2: $ \\overline{\\forall x,\\exists y:\\left[ \\left( \\overline{p\\left( x,y\\right) \\wedge q\\left( x,y\\right) }\\right) \\vee r\\left( x,y\\right) \\right] } $ -> (Aplicamos leyes de Morgan)\n",
    "\n",
    "3: $ \\overline{\\forall x,\\exists y:\\left[ ( \\overline{p\\left( x,y\\right) }\\vee\\overline{q\\left( x,y\\right) }\\vee r\\left( x,y\\right) \\right]} $ -> (Predicado: $\\overline{\\left[ \\forall x,p\\left( x\\right) \\right] }\\leftrightarrow \\exists x:\\overline{p\\left( x\\right) }$)\n",
    "\n",
    "4: $ \\exists x:\\overline{\\exists y:\\left[ ( \\overline{p\\left( x,y\\right) }\\vee\\overline{q\\left( x,y\\right) }\\vee r\\left( x,y\\right) \\right]} $ -> (Predicado: $\\overline{\\exists x:p\\left( x\\right) }\\leftrightarrow \\forall x,\\overline{p\\left( x\\right) }$)\n",
    "\n",
    "5: $ \\exists x:\\forall y,\\overline{\\left[ ( \\overline{p\\left( x,y\\right) }\\vee\\overline{q\\left( x,y\\right) }\\vee r\\left( x,y\\right) \\right]} $ -> (Aplicamos leyes de Morgan)\n",
    "\n",
    "6: $ \\exists x:\\forall y,\\left[ ( \\overline{\\overline{p\\left( x,y\\right) }} \\wedge \\overline{\\overline{q\\left( x,y\\right) }} \\wedge \\overline{r\\left( x,y\\right)} \\right] $ -> (Doble negación)\n",
    "\n",
    "7: $ \\exists x:\\forall y,\\left[ ( p\\left( x,y\\right) \\vee q\\left( x,y\\right) \\vee \\overline{r\\left( x,y\\right)} \\right] $\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b): Resulta una equivalencia ya que : $\\forall x,\\left[ p\\left( x\\right) \\wedge q\\left( x\\right) \\right] \\leftrightarrow \\left[ \\forall x,p\\left( x\\right) \\right] \\wedge \\left[ \\forall x,q\\left( x\\right) \\right] $). \n",
    "\n",
    "Entonces de 7) resolvemos:\n",
    "\n",
    "$ \\exists x:\\forall y,\\left[ ( p\\left( x,y\\right) \\vee q\\left( x,y\\right) \\vee \\overline{r\\left( x,y\\right)} \\right] \\leftrightarrow \\exists x:\\left[ \\left( \\forall y,p\\left( x,y\\right) \\right) \\wedge \\left( \\forall y,q\\left( x,y\\right) \\right) \\wedge \\left( \\forall y,\\overline{r\\left( x,y\\right) }\\right) \\right] $\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2: Sea $A\\in \\mathbb{R} ^{3\\times 3}$ la matriz cuadradada dada por $$A=\\begin{pmatrix} 3 & -3 & 2 \\\\ -4 & 4 & -4 \\\\ -3 & 3 & 2 \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado a) \n",
    "\n",
    "Obténgase cuatro matrices $B\\in \\mathbb{R} ^{3\\times 3}$ tales que $B^{2}=A$\n",
    "\n",
    "Sugerencia: diagonalizar A puede ser de utilidad. Para el proceso de diagonalización, puedes hacer uso de numpy.linalg.eig en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1:\n",
    "\n",
    "Procedemos a obtener la raiz cuadrada de A. Para ello diagonalizamos A para asi generar la siguiente ecuación: $A=PDP^{-1}$\n",
    "\n",
    "Partiendo de esta ecuación podemos realizar la siguiente transformación: $\\sqrt{A}=P\\sqrt{D}P^{-1}$\n",
    "\n",
    "Siendo P la matriz formada por los vectores propios de A como columnas y D la matriz formada por los valores propios de A como diagonal principal.\n",
    "\n",
    "Comenzamos obteniendo los valores y vectores propios de A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores propios:  [-3.69306809e-16+0.j          5.00000000e+00+3.74165739j\n",
      "  5.00000000e+00-3.74165739j] \n",
      "\n",
      "Vectores propios: \n",
      " [[ 7.07106781e-01+0.j         -2.51164010e-01-0.33563203j\n",
      "  -2.51164010e-01+0.33563203j]\n",
      " [ 7.07106781e-01+0.j          2.15283438e-01+0.53701124j\n",
      "   2.15283438e-01-0.53701124j]\n",
      " [ 1.04676050e-17+0.j          6.99671172e-01+0.j\n",
      "   6.99671172e-01-0.j        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Matriz A\n",
    "A = np.mat([    [3, -3, 2],\n",
    "                [-4, 4, -4],\n",
    "                [-3, 3, 3]    ])\n",
    "\n",
    "# Valores propios y vectores propios de A\n",
    "eigVal, P = np.linalg.eig(A)\n",
    "\n",
    "# Uno de los valores propios podemos considerarlo al ser extremadamente pequeño\n",
    "print(\"Valores propios: \", eigVal, \"\\n\\nVectores propios: \\n\", P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2:\n",
    "\n",
    "Una vez obtenidos los valores y vectores propios de A, declaramos una nueva Matriz D con los valores propios en la diagonal principal. Podemos modificar estos valores propios para obtener matrices diferentes B que cumplan $B^{2}=A$. Para ello modificamos el signo de los valores propios dado que sus cuadrados daran el mismo resultado (recordamos que uno de ellos es nulo a pesar de obtener un valor ínfimo).\n",
    "\n",
    "Declaramos 4 matrices diferentes con las siguientes modificaciones. Sean los valores propios: 0, a, b:\n",
    "\n",
    "- 0, -a, b\n",
    "- 0, a, -b\n",
    "- 0, -a, -b\n",
    "- 0, a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de valores propios en la diagonal principal\n",
    "D = np.diag(eigVal)\n",
    "\n",
    "# Matrizes con la raiz cuadrada de los valores propios en la diagonal principal y sus modificaciones:\n",
    "Draiz = np.sqrt(D)\n",
    "Draiz[1] = Draiz[1] * -1\n",
    "\n",
    "Draiz1 = np.sqrt(D)\n",
    "Draiz1[2] = Draiz1[2] * -1\n",
    "\n",
    "Draiz2 = np.sqrt(D)\n",
    "Draiz2[1] = Draiz2[1] * -1\n",
    "Draiz2[2] = Draiz2[2] * -1\n",
    "\n",
    "Draiz3 = np.sqrt(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3:\n",
    "\n",
    "Realizamos $\\sqrt{A}=P\\sqrt{D}P^{-1}$ para cada Draiz[i] obtenida. Tenemos en cuenta que $\\sqrt{A}=B$\n",
    "\n",
    "Estas cuatro matgrices obtenidas son: A2, B2, C2 y D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.74062631e-17  2.07449587e-17  2.86951205e-17]\n",
      " [-2.33551252e-17  2.86977018e-18 -4.73406359e-17]\n",
      " [ 9.46251144e-17 -1.10393362e-18 -1.03415058e-16]] \n",
      "\n",
      "[[ 3.74062631e-17 -2.07449587e-17 -2.86951205e-17]\n",
      " [ 2.33551252e-17 -2.86977018e-18  4.73406359e-17]\n",
      " [-9.46251144e-17  1.10393362e-18  1.03415058e-16]] \n",
      "\n",
      "[[-1.13907847  1.13907847 -0.28666884]\n",
      " [ 1.65383324 -1.65383324  0.97852352]\n",
      " [ 0.63259618 -0.63259618 -1.94945014]] \n",
      "\n",
      "[[ 1.13907847 -1.13907847  0.28666884]\n",
      " [-1.65383324  1.65383324 -0.97852352]\n",
      " [-0.63259618  0.63259618  1.94945014]] \n",
      "\n",
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n",
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n",
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n",
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# Multiplicación de matrices para obtener las 4 matrices pedidas:\n",
    "\n",
    "A1 = np.matmul(P, Draiz)\n",
    "A2 = np.matmul(A1, np.linalg.inv(P))\n",
    "\n",
    "B1 = np.matmul(P, Draiz1)\n",
    "B2 = np.matmul(B1, np.linalg.inv(P))\n",
    "\n",
    "C1 = np.matmul(P, Draiz2)\n",
    "C2 = np.matmul(C1, np.linalg.inv(P))\n",
    "\n",
    "D1 = np.matmul(P, Draiz3)\n",
    "D2 = np.matmul(D1, np.linalg.inv(P))\n",
    "\n",
    "# Las cuatro matrices son: \n",
    "\n",
    "print(A2.real, \"\\n\")\n",
    "print(B2.real, \"\\n\")\n",
    "print(C2.real, \"\\n\")\n",
    "print(D2.real, \"\\n\")\n",
    "\n",
    "# Comprobamos que sus cuadrados cumples que B^2 = A\n",
    "\n",
    "print(np.round(np.matmul(A2, A2)).real.astype(int) == A)\n",
    "print(np.round(np.matmul(B2, B2)).real.astype(int) == A)\n",
    "print(np.round(np.matmul(C2, C2)).real.astype(int) == A)\n",
    "print(np.round(np.matmul(D2, D2)).real.astype(int) == A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado b)\n",
    "¿Crees que las matrices se podrían haber obtenido por tanteo, empleando la fuerza bruta, con un coste computacional similar? ¿Qué nos dice esto, en términos de optimización, acerca de utilizar en determinadas ocasiones estrategias matemáticas en la resolución computacional de problemas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tenemos una matriz $A\\in \\mathbb{R} ^{3\\times 3}$  cuyos elementos están dados por $a_{ij}$. y otra matriz $B\\in \\mathbb{R} ^{3\\times 3}$ cuyos elementos son $b_{ij}$, necesitaríamos iterar sobre cada elemento $a_{ij}$ haciendo cumplir la siguiente ecuación (suponemos los índices circulares sobre ${3\\times 3}$, de tal forma que si $j = 2$, $j + 1 = 0$, y por tanto $b_{ij+1} = b_{i0}$):\n",
    "\n",
    "$a_{ij} = b_{ij}b_{ij} + b_{i+1j}b_{ij+1} + b_{i+2j}b_{ij+2}$\n",
    "\n",
    "Esto debe cumplirse para un total de 9 elementos.\n",
    "\n",
    "Es obvio que el coste computacional de iteración sobre elementos $b_{ij}$ posibles para encontrar solo un elemento $a_{ij}$ es excesivamente grande. Pensemos que debemos usar un total de 6 bucles anidados pues debemos iterar sobre cada elemento de $a_{ij}$ y encontrar 5 valores: $b_{ij}, b_{i+1j}, b_{ij+1}, b_{i+2j}, b_{ij+2}$. Debemos tener en cuenta también la exactitud de resolución del problema, pues debemos dar valores a los elementos $b_{ij}$. Estos valores pueden ser enteros, redondeados a las décimas, centésimas, etc. Cuantos menos decimales menos costoso será pero mucha más imprecisión tendremos.\n",
    "\n",
    "Por tanto el uso de estrategias matemáticas como la diagonalización de la matriz resulta mucho menos costoso en términos computacionales, así como mucho más preciso.\n",
    "\n",
    "La búsqueda sobre elementos por fuerza bruta nos lleva a un anidamiento de bucles que suponen un costo computacional excesivo, mientras que el cálculo de los valores y vectores propios nos da una solución con muchos menos anidamientos de bucles gracias a su estrategia de resolución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3: Prográmese el método de gradient descent para funciones de n variables. \n",
    "\n",
    "La función deberá tener como parámetros de entradas:\n",
    "\n",
    "- El gradiente de la función que se desea minimizar ∇f.\n",
    "- Un valor inicial x0 ∈ Rn.\n",
    "- El ratio de aprendizaje γ (que se asume constante para cada iteración).\n",
    "- Un parámetro de tolerancia tol (con el que finalizar el proceso cuando |f’(x)| < tol). \n",
    "- Un número máximo de iteraciones maxit.\n",
    "\n",
    "La salida de la función deberá ser la aproximació del x que cumple f′(x) ≈ 0, correspondiente a la última iteración realizada en el método.\n",
    "\n",
    "A continuación, aplica el método a los casos siguientes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado a)\n",
    "\n",
    "$ g\\left( x,y\\right) =x^{2}+y^{2}-xy+2y+1 $ con $x_{0}=\\left( 3,4\\right) ,\\gamma =0,01$, tol = 1e-12, maxit=1e5. Contrasta el resultado obtenido numéricamente con el estudio analítico de la función.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estudio analítico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000000e+01 -4.00000000e+00 -2.40000000e+00 -1.44000000e+00\n",
      " -8.64000000e-01 -5.18400000e-01 -3.11040000e-01 -1.86624000e-01\n",
      " -1.11974400e-01 -6.71846400e-02 -4.03107840e-02 -2.41864704e-02\n",
      " -1.45118822e-02 -8.70712934e-03 -5.22427761e-03 -3.13456656e-03\n",
      " -1.88073994e-03 -1.12844396e-03 -6.77066378e-04 -4.06239827e-04\n",
      " -2.43743896e-04 -1.46246338e-04 -8.77478026e-05 -5.26486815e-05\n",
      " -3.15892089e-05 -1.89535254e-05 -1.13721152e-05 -6.82326913e-06\n",
      " -4.09396148e-06 -2.45637689e-06 -1.47382613e-06]\n",
      "[1.00000000e+02 1.20000000e+01 7.20000000e+00 4.32000000e+00\n",
      " 2.59200000e+00 1.55520000e+00 9.33120000e-01 5.59872000e-01\n",
      " 3.35923200e-01 2.01553920e-01 1.20932352e-01 7.25594112e-02\n",
      " 4.35356467e-02 2.61213880e-02 1.56728328e-02 9.40369969e-03\n",
      " 5.64221981e-03 3.38533189e-03 2.03119913e-03 1.21871948e-03\n",
      " 7.31231688e-04 4.38739013e-04 2.63243408e-04 1.57946045e-04\n",
      " 9.47676268e-05 5.68605761e-05 3.41163456e-05 2.04698074e-05\n",
      " 1.22818844e-05 7.36913066e-06 4.42147839e-06]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7fabc0279cd0>]"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gradient_descent(function, gradient, start, learn_rate, n_iter=50, tolerance=1e-06):\n",
    "    vi = np.array([])\n",
    "    vj = np.array([])\n",
    "    vector = start\n",
    "    vi = np.append(vi, [vector])\n",
    "    vj = np.append(vj, function(vector))\n",
    "    for _ in range(n_iter):\n",
    "        diff = -learn_rate * gradient(vector)\n",
    "        if np.all(np.abs(diff) <= tolerance):\n",
    "            break\n",
    "        vector += diff\n",
    "        vi = np.append(vi, [diff])\n",
    "        vj = np.append(vj, [gradient(vector)])\n",
    "    return vector, vi, vj\n",
    "\n",
    "vec, i, j = gradient_descent(function=lambda v: v**2, gradient=lambda v: 2*v, start=10.0, learn_rate=0.2)\n",
    "print(i)\n",
    "print(j)\n",
    "\n",
    "# 100 linearly spaced numbers\n",
    "x = np.linspace(-10,10,100)\n",
    "\n",
    "# the function, which is y = x^2 here\n",
    "y = x**2\n",
    "\n",
    "# setting the axes at the centre\n",
    "\n",
    "plt.plot(i, j, 'b.')\n",
    "# plot the function\n",
    "plt.plot(x,y, 'r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aparatdo b)\n",
    "\n",
    "$ f\\left( x\\right) =3x^{4}+4x^{3}-12x^{2}+7 $\n",
    "\n",
    "- Aplica el método sobre f(x) con $x_{0}$ = 3 γ = 0.001, tol=1e-12, maxit=1e5.\n",
    "- Aplica de nuevo el m ́etodo sobre f(x) con $x_{0}$ = 3, γ = 0.01, tol=1e-12, maxit=1e5.\n",
    "- Contrasta e interpreta los dos resultados obtenidos en los apartados anteriores y compáralos con los m ́ınimos locales obtenidos anal ́ıticamente. ¿Qué influencia puede llegar a tener la elección del ratio de aprendizaje γ?\n",
    "- Aplica nuevamente el método sobre f(x) con $x_{0}$ = 3, γ = 0.1, tol=1e-12, maxit=1e5. Interpreta el resultado.\n",
    "- Finalmente, aplica el método sobre f(x) con $x_{0}$ = 0, γ = 0.001, tol=1e-12, maxit=1e5. Interpreta el resultado y compáralo con el estudio analítico de f. ¿Es correcto el resultado? ¿Por qué? ¿A qué se debe el fenómeno?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tf': conda)",
   "name": "python379jvsc74a57bd00e3b36984b19af1918e567b6ef4427128e64f599ce0f81735987234538bd33aa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}